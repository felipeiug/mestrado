{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a3fea6f",
   "metadata": {},
   "source": [
    "# IA para espacialização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9361a643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import asciichartpy\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import rioxarray as rxr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "from pyproj import Transformer\n",
    "from shapely import Point, distance\n",
    "from rasterio.transform import rowcol\n",
    "from IPython.display import clear_output\n",
    "from utils.consts import SOIL_TYPES, USO_SOLO_CLASS\n",
    "from utils import Infiltrometro\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CyclicLR\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274d9be1",
   "metadata": {},
   "source": [
    "### Device disponível para treinar o modelo MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a5a26024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 1) Dispositivo (GPU se disponível)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6d56c5",
   "metadata": {},
   "source": [
    "### Dataset com os dados para convolução\n",
    "---\n",
    "- O Dataset nesta aplicação é extremamente importante pois irá englobar todas as informações necessárias para espacializar os dado de infiltração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3b88277c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo Tabelas\n",
      "[ True  True  True  True  True  True  True  True  True False False False\n",
      " False False False False False False False False False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Mestrado\\Trabalho Final\\Codigos\\utils\\infiltracao\\infiltrometro.py:156: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  (c1, c2), covariance = curve_fit(self._equation_infiltration, t, I)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len: 84\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.Size([9, 3]))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MeuDataset(Dataset):\n",
    "\n",
    "    def __init__(self, device:torch.device|None=None, eval=False):\n",
    "\n",
    "        self.eval = eval\n",
    "        self.device = device\n",
    "\n",
    "        # Lendo Tabelas\n",
    "        print(\"Lendo Tabelas\")\n",
    "        infil = pd.read_excel(r\"D:\\Mestrado\\Trabalho Final\\Dados\\Levantamento em Campo\\Compiled.xlsx\", sheet_name=\"Infiltracao\")\n",
    "        self.infil = Infiltrometro(infil)\n",
    "        self.Ks = self.infil.Ks(is_print=False)[\"Ks\"].values.astype(np.float64) # type:ignore\n",
    "        self.Ks = torch.tensor(self.Ks, device=self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.infil.infiltrations)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        idx = i\n",
    "        if isinstance(i, (int, float)):\n",
    "            idx = [i]\n",
    "\n",
    "        sand = torch.tensor(self.infil.infiltrations[\"Sand\"].values[idx], device=self.device) # type:ignore\n",
    "        silt = torch.tensor(self.infil.infiltrations[\"Silt\"].values[idx], device=self.device) # type:ignore\n",
    "        clay = torch.tensor(self.infil.infiltrations[\"Clay\"].values[idx], device=self.device) # type:ignore\n",
    "\n",
    "        # Demais dados\n",
    "        Ks = (-torch.log10(self.Ks[idx]))*1000 # type:ignore\n",
    "        X = torch.stack([sand, silt, clay], dim=1)\n",
    "\n",
    "        if isinstance(i, (int, float)):\n",
    "            X = X[0]\n",
    "            Ks = Ks[0]\n",
    "\n",
    "\n",
    "        return (X, ), Ks\n",
    "    \n",
    "dataset = MeuDataset(device=device)\n",
    "\n",
    "print(\"Len:\", len(dataset))\n",
    "dataset[15][0][0].shape, dataset[1:10][0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d1aafd",
   "metadata": {},
   "source": [
    "### Configurações do treino\n",
    "---\n",
    "\n",
    "- Seed para números aleatórios\n",
    "- % de treino e teste\n",
    "- Métricas\n",
    "- Epochs\n",
    "- Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d3d2664a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed para permitir reprodutibilidade dos valores pseudo-aleatórios\n",
    "seed = 42\n",
    "\n",
    "# Porcentagens de Treino e Teste\n",
    "train_percent = 80\n",
    "test_percent  = 20\n",
    "\n",
    "# BatchSize e Epochs\n",
    "batch_size = 2\n",
    "epochs     = 1000  # Poucos pontos, verificar overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9baf77e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N Total: 84 N Train: 67 N Teste: 17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 3]), torch.Size([4, 3]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(dataset)\n",
    "n_train = int(train_percent*n/100)\n",
    "n_test = n - n_train\n",
    "g = torch.Generator().manual_seed(seed)\n",
    "\n",
    "train_ds, test_ds = random_split(dataset, [n_train, n_test], generator=g)\n",
    "\n",
    "print(\"N Total:\", n, \"N Train:\", n_train, \"N Teste:\", n_test)\n",
    "\n",
    "train_ds[1:5][0][0].shape, test_ds[1:5][0][0].shape # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd0f5b7",
   "metadata": {},
   "source": [
    "### MLP e CNN\n",
    "---\n",
    "\n",
    "MLP configurada com uma CNN também"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3b64aa68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3167],\n",
       "        [-0.3579],\n",
       "        [-0.3483]], device='cuda:0', dtype=torch.float64,\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo (MLP e CNN)\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(3, 16),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),\n",
    "        ).to(dtype=torch.float64)\n",
    "\n",
    "    def forward(self, values):\n",
    "        x = self.fc(values)\n",
    "        return x\n",
    "\n",
    "mlp = MLP().to(device=device)\n",
    "\n",
    "X = dataset[1:4][0]\n",
    "mlp(*X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f9fcac",
   "metadata": {},
   "source": [
    "### Ajustar o modelo MLP\n",
    "\n",
    "- Processos para ajustar a MLP pelo método do gradiente descendente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a5f89fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nse(y_pred, y_true, mean=None):\n",
    "    if mean is not None:\n",
    "        y_true_mean = mean\n",
    "    else:\n",
    "        y_true_mean = torch.mean(y_true)\n",
    "        \n",
    "    numerator = torch.sum((y_pred - y_true) ** 2)\n",
    "    denominator = torch.sum((y_true - y_true_mean) ** 2)\n",
    "    return 1 - (numerator / denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5f431267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176/1000 | Train Loss: 457881.3587 | Val Loss: 425244.4266 | NASH: -0.016114 | At lr:2.5075e-02\n",
      "2403348.12  ┤\n",
      "2274466.30  ┼──╮\n",
      "2145584.48  ┤  ╰╮\n",
      "2016702.67  ┤   │\n",
      "1887820.85  ┤   │\n",
      "1758939.03  ┤   │\n",
      "1630057.22  ┤   │\n",
      "1501175.40  ┤   │\n",
      "1372293.58  ┤   ╰╮\n",
      "1243411.77  ┤    │\n",
      "1114529.95  ┤    │                                                   ╭╮\n",
      "985648.14  ┤    │                                                   ││\n",
      "856766.32  ┤    │                                          ╭╮       ││                ╭╮\n",
      "727884.50  ┤    │                                 ╭╮       ││       ││   ╭╮           ││               ╭─╮\n",
      "599002.69  ┤    │           ╭╮     ╭╮  ╭╮╭╮╭╮    ╭╯│ ╭╮    │╰─╮  ╭╮╭╯│  ╭╯│    ╭╮╭╮   │╰╮      ╭╮  ╭╮ ╭╯ │╭──╮    ╭─╮╭╮         ╭─╮    ╭╮          ╭╮\n",
      "470120.87  ┤    ╰───────────╯╰─────╯╰──╯╰╯╰╯╰────╯ ╰─╯╰──╮╭╯  ╰──╯││ ╰──╯ ╰────╯╰╯╰───╯ ╰──────╯╰──╯╰─╯  ╰╯  ╰────╯ ╰╯╰─────────╯ ╰────╯╰──────────╯╰────────────\n",
      "341239.05  ┤                                             ╰╯       ╰╯\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[98]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[32m     34\u001b[39m     optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     y_sim = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m     loss = criterion(y_sim[:, \u001b[32m0\u001b[39m], y)\n\u001b[32m     38\u001b[39m     running_loss += loss.item() * x[\u001b[32m0\u001b[39m].size(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Mestrado\\Trabalho Final\\Codigos\\libs\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Mestrado\\Trabalho Final\\Codigos\\libs\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[96]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mMLP.forward\u001b[39m\u001b[34m(self, values)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, values):\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Mestrado\\Trabalho Final\\Codigos\\libs\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Mestrado\\Trabalho Final\\Codigos\\libs\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Mestrado\\Trabalho Final\\Codigos\\libs\\Lib\\site-packages\\torch\\nn\\modules\\container.py:244\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    243\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Mestrado\\Trabalho Final\\Codigos\\libs\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Mestrado\\Trabalho Final\\Codigos\\libs\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Mestrado\\Trabalho Final\\Codigos\\libs\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "os.makedirs(\"best_model/\", exist_ok=True)\n",
    "\n",
    "# Média dos valores para compara erros\n",
    "mean = dataset[:][1].mean()\n",
    "\n",
    "model = MLP().to(device=device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = CyclicLR(\n",
    "    optimizer,\n",
    "    base_lr=0.0001,      # menor LR\n",
    "    max_lr=0.1,          # maior LR\n",
    "    step_size_up=100,    # número de iterações até atingir o max_lr\n",
    "    mode='exp_range',   # 'triangular', 'triangular2' ou 'exp_range'\n",
    "    cycle_momentum=True  # necessário se usar Adam em vez de SGD\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds, batch_size=batch_size)\n",
    "\n",
    "best_test_loss = -torch.inf\n",
    "best_state = None\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    # --- treino ---\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for x, y in train_loader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_sim = model(*x)\n",
    "\n",
    "        loss = criterion(y_sim[:, 0], y)\n",
    "        running_loss += loss.item() * x[0].size(0)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_loss = running_loss / len(train_loader.dataset) # type: ignore\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # --- validação ---\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    nash = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            # Forward\n",
    "            y_sim = model(*x)\n",
    "\n",
    "            loss = criterion(y_sim[:, 0], y)\n",
    "            val_loss += loss.item() * x[0].size(0)\n",
    "\n",
    "            ns = nse(y_sim[:, 0], y, mean)\n",
    "            nash += ns.item() * x[0].size(0)\n",
    "\n",
    "    # Média do loss\n",
    "    val_loss /= len(test_loader.dataset) # type: ignore\n",
    "    nash /= len(test_loader.dataset)     # type: ignore\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    # early stopping simples\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    if nash > best_test_loss and epoch > 100:\n",
    "        best_test_loss = nash\n",
    "        best_state = {\n",
    "            \"lr\":current_lr,\n",
    "            \"epoch\": epoch,\n",
    "            \"epochs\":epochs,\n",
    "            \"nash\":nash,\n",
    "            \"val_loss\":val_loss,\n",
    "            \"train_loss\":train_loss,\n",
    "            \"batch_size\":batch_size,\n",
    "            \"model_state\":model.state_dict(),\n",
    "        }\n",
    "\n",
    "        torch.save(best_state, f\"best_model/{str(nash).replace(\".\", \"_\")}.pth\")\n",
    "\n",
    "    # Altero a taxa de aprendizado a cada fim da epoch para melhorar o aprendizado\n",
    "    scheduler.step()\n",
    "\n",
    "    #Print das métricas atuais\n",
    "\n",
    "    indices = np.linspace(0, len(val_losses) - 1, 150, dtype=int)\n",
    "    subset = [val_losses[i] for i in indices]\n",
    "\n",
    "    ascii_chart = asciichartpy.plot(subset, {'height': 15})\n",
    "\n",
    "    # Limpo o terminal\n",
    "    clear_output(wait=True)\n",
    "    print(f\"Epoch {epoch}/{epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | NASH: {(nash):.6f} | At lr:{current_lr:.4e}\\n{ascii_chart}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "libs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
