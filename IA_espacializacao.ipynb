{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a3fea6f",
   "metadata": {},
   "source": [
    "# IA para espacialização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9361a643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rioxarray as rxr\n",
    "\n",
    "from pyproj import Transformer\n",
    "from rasterio.transform import rowcol\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274d9be1",
   "metadata": {},
   "source": [
    "### Device disponível para rodas a RNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5a26024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 1) Dispositivo (GPU se disponível)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6d56c5",
   "metadata": {},
   "source": [
    "## Dataset com os dados para convolução\n",
    "---\n",
    "- O Dataset nesta aplicação é extremamente importante pois irá englobar todas as informações necessárias para espacializar os dado de infiltração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3b88277c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo Tabelas\n",
      "Lendo Rasteres\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.0057], dtype=torch.float64),\n",
       " tensor([0.0092, 0.0025, 0.0012], dtype=torch.float64))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Dataset\n",
    "class MeuDataset(Dataset):\n",
    "    nix_bands = [\n",
    "        \"R400 nm\", \"R410 nm\", \"R420 nm\", \"R430 nm\",\n",
    "        \"R440 nm\", \"R450 nm\", \"R460 nm\", \"R470 nm\",\n",
    "        \"R480 nm\", \"R490 nm\", \"R500 nm\", \"R510 nm\",\n",
    "        \"R520 nm\", \"R530 nm\", \"R540 nm\", \"R550 nm\",\n",
    "        \"R560 nm\", \"R570 nm\", \"R580 nm\", \"R590 nm\",\n",
    "        \"R600 nm\", \"R610 nm\", \"R620 nm\", \"R630 nm\",\n",
    "        \"R640 nm\", \"R650 nm\", \"R660 nm\", \"R670 nm\",\n",
    "        \"R680 nm\", \"R690 nm\", \"R700 nm\",\n",
    "    ]\n",
    "\n",
    "    columns_dados = [\"Ponto\", \"Lat\", \"Lon\", \"Clay\", \"Silt\", \"Sand\", \"K (C1)\"]\n",
    "\n",
    "    def __init__(self, janela:int, device:torch.device|None=None):\n",
    "        self.device = device\n",
    "        self.janela = janela # Janela deve ser ímpar\n",
    "\n",
    "        if self.janela%2 == 0:\n",
    "            raise ValueError(\"A janela deve ser ímpar\")\n",
    "\n",
    "        # Lendo Tabelas\n",
    "        print(\"Lendo Tabelas\")\n",
    "        self.dados = pd.read_excel(r\"D:\\Mestrado\\Trabalho Final\\Dados\\Levantamento em Campo\\Compiled.xlsx\", sheet_name=\"Infiltracao\")\n",
    "        self.dados = self.dados[self.columns_dados].dropna().reset_index(drop=True)\n",
    "        gdf = gpd.GeoDataFrame(self.dados, geometry=gpd.points_from_xy(self.dados[\"Lat\"], self.dados[\"Lon\"]), crs=\"EPSG:4326\")\n",
    "        gdf.to_crs(\"EPSG:31983\", inplace=True)\n",
    "        self.dados['Lat'] = gdf.geometry.y\n",
    "        self.dados['Lon'] = gdf.geometry.x\n",
    "\n",
    "        self.nix = pd.read_excel(r\"D:\\Mestrado\\Trabalho Final\\Dados\\Levantamento em Campo\\Compiled.xlsx\", sheet_name=\"Nix\")\n",
    "        self.pXRF = pd.read_excel(r\"D:\\Mestrado\\Trabalho Final\\Dados\\Levantamento em Campo\\Compiled.xlsx\", sheet_name=\"pXRF\")\n",
    "\n",
    "        # Lendo Rasteres importantes\n",
    "        self.talvegues = gpd.read_file(r\"D:/Mestrado/Trabalho Final/SIG/HidrografiaArea.zip\")\n",
    "\n",
    "        # Lendo Rasteres\n",
    "        print(\"Lendo Rasteres\")\n",
    "        self.uso_solo        = rxr.open_rasterio(r\"D:/Mestrado/Trabalho Final/SIG/USOSOLO.tif\")                 # Tipos de uso do solo\n",
    "        self.elevation       = rxr.open_rasterio(r\"D:/Mestrado/Trabalho Final/SIG/Elevation.tif\")               # Elevação\n",
    "        self.terrain_rug_idx = rxr.open_rasterio(r\"D:/Mestrado/Trabalho Final/SIG/TerrainRuggednessIndex.tif\")  # Variação de elevação entre um pixel e seus vizinhos imediatos\n",
    "        self.topo_pos_idx    = rxr.open_rasterio(r\"D:/Mestrado/Trabalho Final/SIG/TopograficPositionIndex.tif\") # Elevação de um ponto com a média da elevação ao redor, topo, vale ou plano\n",
    "        self.roughness       = rxr.open_rasterio(r\"D:/Mestrado/Trabalho Final/SIG/Roughness.tif\")               # A diferença entre a elevação máxima e mínima dentro de uma vizinhança\n",
    "        self.slope           = rxr.open_rasterio(r\"D:/Mestrado/Trabalho Final/SIG/Slope.tif\")                   # Declividade\n",
    "        self.aspect          = rxr.open_rasterio(r\"D:/Mestrado/Trabalho Final/SIG/Aspect.tif\")                  # Para onde \"aponta\" a face do terreno\n",
    "\n",
    "        # Dados dos rasteres concatenados\n",
    "        self.raster_data = np.array([\n",
    "            self.uso_solo.values[0],\n",
    "            self.elevation.values[0],\n",
    "            self.terrain_rug_idx.values[0],\n",
    "            self.topo_pos_idx.values[0],\n",
    "            self.roughness.values[0],\n",
    "            self.slope.values[0],\n",
    "            self.aspect.values[0],\n",
    "        ])\n",
    "\n",
    "        self.transformer = Transformer.from_crs(\"EPSG:31983\", self.uso_solo.rio.crs, always_xy=True)\n",
    "        self.transform = self.uso_solo.rio.transform()\n",
    "\n",
    "        self._process_dados()\n",
    "\n",
    "    def _process_dados(self):\n",
    "        # Dados para convolução\n",
    "        x, y = self.transformer.transform(self.dados[\"Lon\"], self.dados[\"Lat\"])\n",
    "        row, col = rowcol(self.transform, x, y)\n",
    "\n",
    "        jan = int((self.janela-1)/2)\n",
    "\n",
    "        start_row = row-jan\n",
    "        end_row   = row+jan\n",
    "\n",
    "        start_col = col-jan\n",
    "        end_col   = col+jan\n",
    "\n",
    "        self.dados['s_row']=start_row\n",
    "        self.dados['e_row']=end_row\n",
    "        self.dados['s_col']=start_col\n",
    "        self.dados['e_col']=end_col\n",
    "\n",
    "        # Distância até o talvegue principal\n",
    "        linhas_unidas = self.talvegues.union_all()\n",
    "        pontos = gpd.GeoSeries(gpd.points_from_xy(self.dados[\"Lon\"], self.dados[\"Lat\"]), crs=\"EPSG:31983\")\n",
    "        dists = pontos.apply(lambda p: p.distance(linhas_unidas))\n",
    "        self.dados[\"dist_talvegue\"] = dists\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dados)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, (int, float)):\n",
    "            idx = [idx]\n",
    "\n",
    "        # Pontos    \n",
    "        pontos = self.dados.loc[idx]\n",
    "\n",
    "        # Valores nos rasteres\n",
    "        rasters_vals = []\n",
    "        for s_row, e_row, s_col, e_col in zip(pontos['s_row'], pontos['e_row'], pontos['s_col'], pontos['e_col']):\n",
    "            rasters_vals.append(self.raster_data[:, s_row:e_row+1, s_col:e_col+1])\n",
    "        \n",
    "        rasters_vals = torch.tensor(np.array(rasters_vals))\n",
    "\n",
    "        # Demais dados\n",
    "        K = torch.tensor(pontos[\"K (C1)\"].values)\n",
    "        dist_talvegue = torch.tensor(pontos[\"dist_talvegue\"].values)\n",
    "\n",
    "        return (rasters_vals, dist_talvegue), K\n",
    "    \n",
    "dataset = MeuDataset(janela = 25, device=device)\n",
    "\n",
    "dataset[15][1], dataset[1:3][1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "libs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
